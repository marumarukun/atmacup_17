{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert:\n",
      "  params:\n",
      "    model_path: microsoft/deberta-v3-large\n",
      "    metric: auc\n",
      "    target_col_class_num: 2\n",
      "    max_length: 192\n",
      "    fp16: true\n",
      "    learning_rate: 2.0e-05\n",
      "    epochs: 3\n",
      "    per_device_train_batch_size: 8\n",
      "    per_device_eval_batch_size: 16\n",
      "    steps: 50\n",
      "    lr_scheduler_type: cosine\n",
      "    weight_decay: 0.01\n",
      "exp_number: '012'\n",
      "run_name: base\n",
      "data:\n",
      "  data_root: ../../data\n",
      "  results_root: ../../results\n",
      "  train_path: ../../data/train.csv\n",
      "  cloth_path: ../../data/clothing_master.csv\n",
      "  test_path: ../../data/test.csv\n",
      "  sample_submission_path: ../../data/sample_submission.csv\n",
      "  results_dir: ../../results/012/base\n",
      "seed: 42\n",
      "n_splits: 5\n",
      "target: Recommended IND\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from datasets import Dataset\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from src.seed import seed_everything\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModel,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "with initialize(config_path=\"config\", version_base=None):\n",
    "    cfg = compose(config_name=\"config\")\n",
    "    cfg.exp_number = Path().resolve().name\n",
    "\n",
    "print(OmegaConf.to_yaml(cfg, resolve=True))\n",
    "\n",
    "seed_everything(cfg.seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### exp011をベースに下記変更\n",
    "- Title, Review Text以外Age, Class Name, Positive Feedback Countのカラムも使用\n",
    "- learning_rateを1e-5 --> 2e-5に変更\n",
    "- stepsを25 --> 50に変更\n",
    "- Smooth Focal Lossを使用 --> smoothing=0にする（smoothing=0.1はあまり効果がなかったと思う）\n",
    "  - https://www.kaggle.com/c/nbme-score-clinical-patient-notes/discussion/322799#1781528 を参考に実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データの準備\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pl.read_csv(cfg.data.train_path, try_parse_dates=True)\n",
    "test_df = pl.read_csv(cfg.data.test_path, try_parse_dates=True)\n",
    "cloth_df = pl.read_csv(cfg.data.cloth_path, try_parse_dates=True)\n",
    "\n",
    "train_df = train_df.join(cloth_df, on=\"Clothing ID\", how=\"left\")\n",
    "test_df = test_df.join(cloth_df, on=\"Clothing ID\", how=\"left\")\n",
    "\n",
    "skf = StratifiedKFold(n_splits=cfg.n_splits, shuffle=True, random_state=cfg.seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Clothing ID</th><th>Age</th><th>Title</th><th>Review Text</th><th>Rating</th><th>Recommended IND</th><th>Positive Feedback Count</th><th>Division Name</th><th>Department Name</th><th>Class Name</th></tr><tr><td>i64</td><td>i64</td><td>str</td><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>0</td><td>25</td><td>&quot;3-season skirt!&quot;</td><td>&quot;Adorable, well-made skirt! lin…</td><td>5</td><td>1</td><td>4</td><td>&quot;General&quot;</td><td>&quot;Bottoms&quot;</td><td>&quot;Skirts&quot;</td></tr><tr><td>0</td><td>39</td><td>&quot;Very cute&quot;</td><td>&quot;Love the asymmetrical hem. wai…</td><td>5</td><td>1</td><td>0</td><td>&quot;General&quot;</td><td>&quot;Bottoms&quot;</td><td>&quot;Skirts&quot;</td></tr><tr><td>0</td><td>42</td><td>&quot;Beautiful! fruns small for typ…</td><td>&quot;I love this skirt! i wasn&#x27;t su…</td><td>5</td><td>1</td><td>5</td><td>&quot;General&quot;</td><td>&quot;Bottoms&quot;</td><td>&quot;Skirts&quot;</td></tr><tr><td>0</td><td>45</td><td>null</td><td>&quot;I was really pleased with this…</td><td>5</td><td>1</td><td>9</td><td>&quot;General&quot;</td><td>&quot;Bottoms&quot;</td><td>&quot;Skirts&quot;</td></tr><tr><td>0</td><td>57</td><td>&quot;Unique, pretty asymmetric skir…</td><td>&quot;I saw this skirt in retailer s…</td><td>5</td><td>1</td><td>1</td><td>&quot;General&quot;</td><td>&quot;Bottoms&quot;</td><td>&quot;Skirts&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 10)\n",
       "┌─────────────┬─────┬─────────────┬────────────┬───┬────────────┬────────────┬────────────┬────────┐\n",
       "│ Clothing ID ┆ Age ┆ Title       ┆ Review     ┆ … ┆ Positive   ┆ Division   ┆ Department ┆ Class  │\n",
       "│ ---         ┆ --- ┆ ---         ┆ Text       ┆   ┆ Feedback   ┆ Name       ┆ Name       ┆ Name   │\n",
       "│ i64         ┆ i64 ┆ str         ┆ ---        ┆   ┆ Count      ┆ ---        ┆ ---        ┆ ---    │\n",
       "│             ┆     ┆             ┆ str        ┆   ┆ ---        ┆ str        ┆ str        ┆ str    │\n",
       "│             ┆     ┆             ┆            ┆   ┆ i64        ┆            ┆            ┆        │\n",
       "╞═════════════╪═════╪═════════════╪════════════╪═══╪════════════╪════════════╪════════════╪════════╡\n",
       "│ 0           ┆ 25  ┆ 3-season    ┆ Adorable,  ┆ … ┆ 4          ┆ General    ┆ Bottoms    ┆ Skirts │\n",
       "│             ┆     ┆ skirt!      ┆ well-made  ┆   ┆            ┆            ┆            ┆        │\n",
       "│             ┆     ┆             ┆ skirt!     ┆   ┆            ┆            ┆            ┆        │\n",
       "│             ┆     ┆             ┆ lin…       ┆   ┆            ┆            ┆            ┆        │\n",
       "│ 0           ┆ 39  ┆ Very cute   ┆ Love the   ┆ … ┆ 0          ┆ General    ┆ Bottoms    ┆ Skirts │\n",
       "│             ┆     ┆             ┆ asymmetric ┆   ┆            ┆            ┆            ┆        │\n",
       "│             ┆     ┆             ┆ al hem.    ┆   ┆            ┆            ┆            ┆        │\n",
       "│             ┆     ┆             ┆ wai…       ┆   ┆            ┆            ┆            ┆        │\n",
       "│ 0           ┆ 42  ┆ Beautiful!  ┆ I love     ┆ … ┆ 5          ┆ General    ┆ Bottoms    ┆ Skirts │\n",
       "│             ┆     ┆ fruns small ┆ this       ┆   ┆            ┆            ┆            ┆        │\n",
       "│             ┆     ┆ for typ…    ┆ skirt! i   ┆   ┆            ┆            ┆            ┆        │\n",
       "│             ┆     ┆             ┆ wasn't su… ┆   ┆            ┆            ┆            ┆        │\n",
       "│ 0           ┆ 45  ┆ null        ┆ I was      ┆ … ┆ 9          ┆ General    ┆ Bottoms    ┆ Skirts │\n",
       "│             ┆     ┆             ┆ really     ┆   ┆            ┆            ┆            ┆        │\n",
       "│             ┆     ┆             ┆ pleased    ┆   ┆            ┆            ┆            ┆        │\n",
       "│             ┆     ┆             ┆ with this… ┆   ┆            ┆            ┆            ┆        │\n",
       "│ 0           ┆ 57  ┆ Unique,     ┆ I saw this ┆ … ┆ 1          ┆ General    ┆ Bottoms    ┆ Skirts │\n",
       "│             ┆     ┆ pretty      ┆ skirt in   ┆   ┆            ┆            ┆            ┆        │\n",
       "│             ┆     ┆ asymmetric  ┆ retailer   ┆   ┆            ┆            ┆            ┆        │\n",
       "│             ┆     ┆ skir…       ┆ s…         ┆   ┆            ┆            ┆            ┆        │\n",
       "└─────────────┴─────┴─────────────┴────────────┴───┴────────────┴────────────┴────────────┴────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "\n",
    "if DEBUG:\n",
    "    train_df = train_df.head(1000)\n",
    "\n",
    "\n",
    "def preprocess_text(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    df = df.with_columns(\n",
    "        pl.concat_str(\n",
    "            [\n",
    "                pl.col(\"Age\").fill_null(\"none\"),\n",
    "                pl.lit(\"-Year-Old's Review of \"),\n",
    "                pl.col(\"Class Name\").fill_null(\"none\"),\n",
    "                pl.lit(\" [SEP] \"),\n",
    "                pl.lit(\"TITLE: \"),\n",
    "                pl.col(\"Title\").fill_null(\"none\"),\n",
    "                pl.lit(\" [SEP] \"),\n",
    "                pl.lit(\"Review Text: \"),\n",
    "                pl.col(\"Review Text\").fill_null(\"none\"),\n",
    "                pl.lit(\" [SEP] \"),\n",
    "                pl.lit(\"Positive Feedback Count: \"),\n",
    "                pl.col(\"Positive Feedback Count\").fill_null(\"none\"),\n",
    "            ]\n",
    "        ).alias(\"prompt\")\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "train_df = preprocess_text(train_df)\n",
    "test_df = preprocess_text(test_df)\n",
    "\n",
    "train_df = train_df.with_columns(pl.col(cfg.target).cast(pl.Int8).alias(\"labels\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"25-Year-Old's Review of Skirts [SEP] TITLE: 3-season skirt! [SEP] Review Text: Adorable, well-made skirt! lined and very slimming. i had to size up b/c it runs a bit snug around the waist. however, it's worth it b/c this will match many long and short sleeve tops! [SEP] Positive Feedback Count: 4\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt例\n",
    "train_df[\"prompt\"][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(cfg.bert.params.model_path)\n",
    "\n",
    "\n",
    "def tokenize(sample):\n",
    "    return tokenizer(sample[\"prompt\"], max_length=cfg.bert.params.max_length, truncation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df: 185\n",
      "test_df: 184\n"
     ]
    }
   ],
   "source": [
    "# token長を確認 --> max_length 192で耐えてる\n",
    "print(\n",
    "    f\"train_df: {train_df.select(pl.col('prompt').map_elements(lambda x: len(tokenizer(x)['input_ids']))).max().item()}\"\n",
    ")\n",
    "print(\n",
    "    f\"test_df: {test_df.select(pl.col('prompt').map_elements(lambda x: len(tokenizer(x)['input_ids']))).max().item()}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoth Focal Loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, reduction=\"none\", alpha=1, gamma=2):\n",
    "        super().__init__()\n",
    "        self.reduction = reduction\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        bce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction=\"none\")\n",
    "        pt = torch.exp(-bce_loss)\n",
    "        loss = self.alpha * (1.0 - pt) ** self.gamma * bce_loss\n",
    "        if self.reduction == \"none\":\n",
    "            loss = loss\n",
    "        elif self.reduction == \"sum\":\n",
    "            loss = loss.sum()\n",
    "        elif self.reduction == \"mean\":\n",
    "            loss = loss.mean()\n",
    "        return loss\n",
    "\n",
    "\n",
    "class SmoothFocalLoss(nn.Module):\n",
    "    def __init__(self, reduction=\"mean\", alpha=1, gamma=2, smoothing=0.0):\n",
    "        super().__init__()\n",
    "        self.reduction = reduction\n",
    "        self.focal_loss = FocalLoss(reduction=\"none\", alpha=alpha, gamma=gamma)\n",
    "        self.smoothing = smoothing\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth(targets: torch.Tensor, smoothing=0.0):\n",
    "        assert 0 <= smoothing < 1\n",
    "        with torch.no_grad():\n",
    "            targets = targets * (1.0 - smoothing) + 0.5 * smoothing\n",
    "        return targets\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = SmoothFocalLoss._smooth(targets, self.smoothing)\n",
    "        loss = self.focal_loss(inputs, targets)\n",
    "        if self.reduction == \"none\":\n",
    "            loss = loss\n",
    "        elif self.reduction == \"sum\":\n",
    "            loss = loss.sum()\n",
    "        elif self.reduction == \"mean\":\n",
    "            loss = loss.mean()\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    def __init__(self, loss_fn=None, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        if self.loss_fn is None:\n",
    "            loss = F.cross_entropy(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        else:\n",
    "            # ロジットとラベルの形状を調整\n",
    "            logits = logits[:, 1]  # ポジティブクラスのロジットのみを使用\n",
    "            labels = labels.float()\n",
    "            loss = self.loss_fn(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "\n",
    "# Smooth Focal Lossのインスタンスを作成\n",
    "loss_fn = SmoothFocalLoss(alpha=1, gamma=2, smoothing=0)  # 結局gammaしか効かしてない\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed57f79a0966407ca51acacd22c6bd2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bae8a9fd3062428ab23268a790b6844d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [750/750 19:09, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.154400</td>\n",
       "      <td>0.115337</td>\n",
       "      <td>0.777087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.075600</td>\n",
       "      <td>0.081926</td>\n",
       "      <td>0.918364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.056300</td>\n",
       "      <td>0.049485</td>\n",
       "      <td>0.966710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.056600</td>\n",
       "      <td>0.058839</td>\n",
       "      <td>0.967298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.052600</td>\n",
       "      <td>0.046742</td>\n",
       "      <td>0.971510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.041300</td>\n",
       "      <td>0.043498</td>\n",
       "      <td>0.973031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.033000</td>\n",
       "      <td>0.050944</td>\n",
       "      <td>0.970073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.038400</td>\n",
       "      <td>0.038271</td>\n",
       "      <td>0.975470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.041600</td>\n",
       "      <td>0.042089</td>\n",
       "      <td>0.975527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.047400</td>\n",
       "      <td>0.038747</td>\n",
       "      <td>0.976048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>0.040460</td>\n",
       "      <td>0.976145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.024900</td>\n",
       "      <td>0.044369</td>\n",
       "      <td>0.975395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.020300</td>\n",
       "      <td>0.048403</td>\n",
       "      <td>0.974733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.045680</td>\n",
       "      <td>0.975396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.022200</td>\n",
       "      <td>0.045644</td>\n",
       "      <td>0.975415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bc4b5d3de2c4367a822a6c0680b3410",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e6b532fb5e0443d80c1329267f59ee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [750/750 17:44, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.154200</td>\n",
       "      <td>0.110153</td>\n",
       "      <td>0.872783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.075400</td>\n",
       "      <td>0.056047</td>\n",
       "      <td>0.961213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.063400</td>\n",
       "      <td>0.050880</td>\n",
       "      <td>0.966813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.053300</td>\n",
       "      <td>0.049276</td>\n",
       "      <td>0.973198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.047700</td>\n",
       "      <td>0.047934</td>\n",
       "      <td>0.969970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.044200</td>\n",
       "      <td>0.042629</td>\n",
       "      <td>0.971142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.038400</td>\n",
       "      <td>0.042911</td>\n",
       "      <td>0.973078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.040600</td>\n",
       "      <td>0.044638</td>\n",
       "      <td>0.972246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.037800</td>\n",
       "      <td>0.045818</td>\n",
       "      <td>0.972880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.046240</td>\n",
       "      <td>0.973105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.023800</td>\n",
       "      <td>0.058153</td>\n",
       "      <td>0.969804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.023900</td>\n",
       "      <td>0.056826</td>\n",
       "      <td>0.970250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.021500</td>\n",
       "      <td>0.059600</td>\n",
       "      <td>0.968229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.021900</td>\n",
       "      <td>0.053859</td>\n",
       "      <td>0.969985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.022100</td>\n",
       "      <td>0.054017</td>\n",
       "      <td>0.969888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2234d3d4c7cc4d89bbbdf8e0d9386547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95096a625c4541d1981ca8ad118603d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [750/750 18:40, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.157000</td>\n",
       "      <td>0.119721</td>\n",
       "      <td>0.837587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.090300</td>\n",
       "      <td>0.070617</td>\n",
       "      <td>0.953506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.053800</td>\n",
       "      <td>0.049113</td>\n",
       "      <td>0.965335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.053000</td>\n",
       "      <td>0.045548</td>\n",
       "      <td>0.970678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.043000</td>\n",
       "      <td>0.058293</td>\n",
       "      <td>0.972276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.041900</td>\n",
       "      <td>0.052848</td>\n",
       "      <td>0.970879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>0.051571</td>\n",
       "      <td>0.972210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.040500</td>\n",
       "      <td>0.049375</td>\n",
       "      <td>0.972243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.043500</td>\n",
       "      <td>0.047532</td>\n",
       "      <td>0.972232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>0.049739</td>\n",
       "      <td>0.973452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>0.057514</td>\n",
       "      <td>0.972137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.029900</td>\n",
       "      <td>0.052508</td>\n",
       "      <td>0.972003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.017500</td>\n",
       "      <td>0.060545</td>\n",
       "      <td>0.970557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.019700</td>\n",
       "      <td>0.060529</td>\n",
       "      <td>0.970418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.060096</td>\n",
       "      <td>0.970628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e115d524a344862afac5f54d63dd1df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08e30931f3134cb68ff1d241957af582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [750/750 14:36, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.157100</td>\n",
       "      <td>0.105030</td>\n",
       "      <td>0.901187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.101000</td>\n",
       "      <td>0.109009</td>\n",
       "      <td>0.870957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.063000</td>\n",
       "      <td>0.081631</td>\n",
       "      <td>0.961422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.063800</td>\n",
       "      <td>0.060162</td>\n",
       "      <td>0.962331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.055500</td>\n",
       "      <td>0.049807</td>\n",
       "      <td>0.964394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.037300</td>\n",
       "      <td>0.061504</td>\n",
       "      <td>0.965343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.043300</td>\n",
       "      <td>0.048685</td>\n",
       "      <td>0.964286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.031800</td>\n",
       "      <td>0.048261</td>\n",
       "      <td>0.968398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.039700</td>\n",
       "      <td>0.051036</td>\n",
       "      <td>0.971054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.041900</td>\n",
       "      <td>0.051569</td>\n",
       "      <td>0.968262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.024800</td>\n",
       "      <td>0.064223</td>\n",
       "      <td>0.968752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>0.057008</td>\n",
       "      <td>0.969686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>0.056557</td>\n",
       "      <td>0.970107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.024300</td>\n",
       "      <td>0.055806</td>\n",
       "      <td>0.970056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>0.055235</td>\n",
       "      <td>0.969894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c451a17901b74a02b2ff700816588fa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "791aabac8a254707a1a1845e28f88d80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [750/750 14:56, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.152900</td>\n",
       "      <td>0.116163</td>\n",
       "      <td>0.906015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.072100</td>\n",
       "      <td>0.073576</td>\n",
       "      <td>0.951883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.061500</td>\n",
       "      <td>0.056677</td>\n",
       "      <td>0.966788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.059700</td>\n",
       "      <td>0.049377</td>\n",
       "      <td>0.971109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.053300</td>\n",
       "      <td>0.044699</td>\n",
       "      <td>0.973168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.051533</td>\n",
       "      <td>0.971184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.037800</td>\n",
       "      <td>0.046075</td>\n",
       "      <td>0.970277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.040400</td>\n",
       "      <td>0.048181</td>\n",
       "      <td>0.971187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.041800</td>\n",
       "      <td>0.045491</td>\n",
       "      <td>0.972457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.041600</td>\n",
       "      <td>0.053808</td>\n",
       "      <td>0.971773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.026500</td>\n",
       "      <td>0.052618</td>\n",
       "      <td>0.969251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.029900</td>\n",
       "      <td>0.051956</td>\n",
       "      <td>0.968803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.023000</td>\n",
       "      <td>0.053069</td>\n",
       "      <td>0.968802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.024300</td>\n",
       "      <td>0.053380</td>\n",
       "      <td>0.969059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.024700</td>\n",
       "      <td>0.053542</td>\n",
       "      <td>0.969074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# metricをAUCに変更\n",
    "def compute_metrics(p):\n",
    "    preds, labels = p\n",
    "    preds = torch.softmax(torch.tensor(preds), dim=1).numpy()\n",
    "    score = roc_auc_score(labels, preds[:, 1])\n",
    "    return {\"auc\": score}\n",
    "\n",
    "\n",
    "# 実験結果格納用のディレクトリを作成\n",
    "cfg.run_name = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "Path(cfg.data.results_dir).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "y_train = train_df[cfg.target].to_numpy()\n",
    "oof = np.zeros(len(y_train))\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, y_train)):\n",
    "    ds_train = Dataset.from_pandas(train_df[train_idx][[\"prompt\", \"labels\"]].clone().to_pandas())\n",
    "    ds_val = Dataset.from_pandas(train_df[val_idx][[\"prompt\", \"labels\"]].clone().to_pandas())\n",
    "\n",
    "    config = AutoConfig.from_pretrained(cfg.bert.params.model_path)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(cfg.bert.params.model_path, config=config)\n",
    "\n",
    "    ds_train = ds_train.map(tokenize).remove_columns(\"prompt\")\n",
    "    ds_val = ds_val.map(tokenize).remove_columns(\"prompt\")\n",
    "\n",
    "    output_dir = os.path.join(cfg.data.results_dir, f\"fold{fold}\")\n",
    "\n",
    "    train_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        fp16=cfg.bert.params.fp16,\n",
    "        learning_rate=cfg.bert.params.learning_rate,\n",
    "        num_train_epochs=cfg.bert.params.epochs,\n",
    "        per_device_train_batch_size=cfg.bert.params.per_device_train_batch_size,\n",
    "        per_device_eval_batch_size=cfg.bert.params.per_device_eval_batch_size,\n",
    "        gradient_accumulation_steps=4,\n",
    "        report_to=\"none\",\n",
    "        evaluation_strategy=\"steps\",\n",
    "        do_eval=True,\n",
    "        eval_steps=cfg.bert.params.steps,\n",
    "        save_total_limit=1,\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=cfg.bert.params.steps,\n",
    "        logging_steps=cfg.bert.params.steps,\n",
    "        load_best_model_at_end=True,\n",
    "        lr_scheduler_type=cfg.bert.params.lr_scheduler_type,\n",
    "        metric_for_best_model=cfg.bert.params.metric,\n",
    "        greater_is_better=True,\n",
    "        warmup_ratio=0.1,\n",
    "        weight_decay=cfg.bert.params.weight_decay,\n",
    "        save_safetensors=True,\n",
    "        seed=cfg.seed,\n",
    "        data_seed=cfg.seed,\n",
    "    )\n",
    "\n",
    "    trainer = CustomTrainer(\n",
    "        model=model,\n",
    "        args=train_args,\n",
    "        train_dataset=ds_train,\n",
    "        eval_dataset=ds_val,\n",
    "        data_collator=DataCollatorWithPadding(tokenizer),\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "        loss_fn=loss_fn,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    final_output_dir = f\"{cfg.data.results_dir}/fold{fold}/final\"\n",
    "    trainer.save_model(final_output_dir)\n",
    "    tokenizer.save_pretrained(final_output_dir)\n",
    "\n",
    "    pred = torch.softmax(torch.tensor(trainer.predict(ds_val).predictions), dim=1).numpy()\n",
    "    oof[val_idx] = pred[:, 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "506f8410e8e847d1b97c5476b5708f00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11155 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6c5d39734d747caa6969420fbae0a68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11155 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad21249eb1a94d02b2358d1b7b619fd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11155 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1655850d1469488aa32f95e03213c68b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11155 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16343421a7e04610b583d6cda6b15762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11155 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = []\n",
    "for fold in range(cfg.n_splits):\n",
    "    # ベストステップのモデルを取得\n",
    "    fold_dir = f\"{cfg.data.results_dir}/fold{fold}\"\n",
    "    checkpoint_dirs = [d for d in os.listdir(fold_dir) if d.startswith(\"checkpoint-\")]\n",
    "    results_dir = os.path.join(fold_dir, checkpoint_dirs[0])\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(results_dir)\n",
    "\n",
    "    ds_test = Dataset.from_pandas(test_df.select(\"prompt\").clone().to_pandas())\n",
    "    ds_test = ds_test.map(tokenize).remove_columns(\"prompt\")\n",
    "\n",
    "    test_args = TrainingArguments(\n",
    "        output_dir=cfg.data.results_dir,\n",
    "        per_device_eval_batch_size=cfg.bert.params.per_device_eval_batch_size,\n",
    "        do_predict=True,\n",
    "        dataloader_drop_last=False,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=test_args,\n",
    "        data_collator=DataCollatorWithPadding(tokenizer),\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "    predictions = torch.softmax(torch.tensor(trainer.predict(ds_test).predictions), dim=1).numpy()\n",
    "    preds.append(predictions[:, 1])\n",
    "\n",
    "pred = np.mean(preds, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>target</th></tr><tr><td>f32</td></tr></thead><tbody><tr><td>0.905986</td></tr><tr><td>0.486497</td></tr><tr><td>0.907969</td></tr><tr><td>0.329067</td></tr><tr><td>0.89087</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 1)\n",
       "┌──────────┐\n",
       "│ target   │\n",
       "│ ---      │\n",
       "│ f32      │\n",
       "╞══════════╡\n",
       "│ 0.905986 │\n",
       "│ 0.486497 │\n",
       "│ 0.907969 │\n",
       "│ 0.329067 │\n",
       "│ 0.89087  │\n",
       "└──────────┘"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 提出\n",
    "sub_df = pl.read_csv(cfg.data.sample_submission_path)\n",
    "sub_df = sub_df.with_columns(pl.Series(pred).alias(\"target\"))\n",
    "sub_df.write_csv(os.path.join(cfg.data.results_dir, f\"{cfg.run_name}_submission.csv\"))\n",
    "sub_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### oof\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "sns.histplot(y_train, bins=50)\n",
    "sns.histplot(oof, bins=50)\n",
    "plt.legend([\"true\", \"oof\"])\n",
    "plt.show()\n",
    "fig.savefig(f\"{cfg.data.results_dir}/oof_hist.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OOFを保存\n",
    "np.save(f\"{cfg.data.results_dir}/oof.npy\", oof)\n",
    "\n",
    "# 予測結果も保存\n",
    "np.save(f\"{cfg.data.results_dir}/pred.npy\", pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習済みのBERTを使って特徴抽出してみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用デバイス: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94627b756a6f48dabd414a405957e1f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "682d4d7612094d98b8b40943e7442a97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fcde349fe714d8faf35a2492ea5cf69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d9218a9656a4f51a2b372d0a6d197e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9540d02bc09a40ceb850c80a698994e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# trainのoofで特徴抽出\n",
    "\n",
    "cfg.run_name = \"20240830_164022\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"使用デバイス: {device}\")\n",
    "\n",
    "\n",
    "# モデルの定義を変更して特徴量を抽出するクラス\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, **inputs):\n",
    "        outputs = self.model(**inputs, output_hidden_states=True)\n",
    "        # 最後の隠れ層の出力を取得（他の層を使用することも可能）\n",
    "        features = outputs.hidden_states[-1][:, 0, :]  # [CLS]トークンの出力を使用\n",
    "        return features\n",
    "\n",
    "\n",
    "# 特徴量抽出用の関数\n",
    "def extract_features(model, dataset, tokenizer):\n",
    "    feature_extractor = FeatureExtractor(model).to(device)\n",
    "    feature_extractor.eval()\n",
    "\n",
    "    features = []\n",
    "    for batch in DataLoader(dataset, batch_size=8, collate_fn=DataCollatorWithPadding(tokenizer)):\n",
    "        with torch.no_grad():\n",
    "            batch = {k: v.to(model.device) for k, v in batch.items()}\n",
    "            output = feature_extractor(**batch)\n",
    "            features.append(output.cpu().numpy())\n",
    "\n",
    "    return np.vstack(features)\n",
    "\n",
    "\n",
    "# OOFデータの特徴量を抽出\n",
    "train_oof_features = []\n",
    "for fold in range(cfg.n_splits):\n",
    "    fold_dir = f\"{cfg.data.results_dir}/fold{fold}\"\n",
    "    checkpoint_dirs = [d for d in os.listdir(fold_dir) if d.startswith(\"checkpoint-\")]\n",
    "    results_dir = os.path.join(fold_dir, checkpoint_dirs[0])\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(results_dir)\n",
    "\n",
    "    # バリデーションデータセットの準備\n",
    "    val_idx = list(skf.split(train_df, y_train))[fold][1]\n",
    "    ds_val = Dataset.from_pandas(train_df[val_idx][[\"prompt\"]].clone().to_pandas())\n",
    "    ds_val = ds_val.map(tokenize).remove_columns(\"prompt\")\n",
    "\n",
    "    # 特徴量抽出\n",
    "    fold_features = extract_features(model, ds_val, tokenizer)\n",
    "    train_oof_features.append(fold_features)\n",
    "\n",
    "\n",
    "# 全てのフォールドの特徴量を結合\n",
    "train_oof_features = np.concatenate(train_oof_features, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_oof_features.shape = (10000, 1024)\n"
     ]
    }
   ],
   "source": [
    "print(f\"{train_oof_features.shape = }\")\n",
    "# 保存\n",
    "np.save(f\"{cfg.data.results_dir}/train_oof_features.npy\", train_oof_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1f0f0643639495d8cae97b2ad06a17f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11155 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dedf2e105e424c8faabb0b5c9c45b5b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11155 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddf84f187fdb44c8acdbcf6651a591ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11155 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf961f72c73c4e07aedba75e1155c153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11155 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0037e88af76049cfb5d71c7c77d16ada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11155 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 次はtestの特徴抽出（fold間での平均を使用する）\n",
    "test_features = []\n",
    "for fold in range(cfg.n_splits):\n",
    "    fold_dir = f\"{cfg.data.results_dir}/fold{fold}\"\n",
    "    checkpoint_dirs = [d for d in os.listdir(fold_dir) if d.startswith(\"checkpoint-\")]\n",
    "    results_dir = os.path.join(fold_dir, checkpoint_dirs[0])\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(results_dir)\n",
    "\n",
    "    ds_test = Dataset.from_pandas(test_df.select(\"prompt\").clone().to_pandas())\n",
    "    ds_test = ds_test.map(tokenize).remove_columns(\"prompt\")\n",
    "\n",
    "    # 特徴量抽出\n",
    "    fold_features = extract_features(model, ds_test, tokenizer)\n",
    "    test_features.append(fold_features)\n",
    "\n",
    "\n",
    "# 全てのフォールドの特徴量の平均をとる\n",
    "test_features = np.mean(test_features, axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_features.shape = (11155, 1024)\n"
     ]
    }
   ],
   "source": [
    "print(f\"{test_features.shape = }\")\n",
    "# 保存\n",
    "np.save(f\"{cfg.data.results_dir}/test_features.npy\", test_features)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
